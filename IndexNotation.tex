\documentclass[a4paper, 11pt]{article}
% TeX-template
% Copyright (c) 2024 Joseph Tooby-Smith. All rights reserved.
% Released under Apache 2.0 license.
% Paper content: 
% Copyright (c) 2024 Joseph Tooby-Smith. All rights reserved.
\usepackage{xcolor}
\usepackage{setspace}
\onehalfspacing%
\usepackage{bbm}
%\setstretch{3} % Custom separation of lines.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Hyperlinks
\usepackage{hyperref}
\definecolor{mycolor}{RGB}{0,88,204}
\hypersetup{
  colorlinks=true,
  linkcolor=mycolor,
  urlcolor=mycolor,
  citecolor=mycolor
}
%%%%%%%%%%%%%
%Watermark
\usepackage{draftwatermark}
\SetWatermarkText{\color{mycolor} DRAFT}
\SetWatermarkScale{1.5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Mathematics
\usepackage{amsmath}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Margins
\usepackage{geometry}

\geometry{
  top=0.8in,
  bottom=0.8in,
  left=1in,
  right=1in
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Page numbers
\usepackage{fancyhdr}


\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{13.6pt}
%For the title page
\fancypagestyle{plain}{%
  \fancyhf{}
  \fancyhead[R]{\thepage}
  \renewcommand{\headrulewidth}{0pt}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Fonts

\usepackage{mathptmx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Section style

\usepackage{titlesec}

\titleformat{\section}
  {\normalfont\large\centering}{\thesection.}{1em}{\MakeUppercase}
\titleformat{\subsection}
  {\normalfont\centering}{\thesubsection.}{1em}{\MakeUppercase}

  \titlespacing{\paragraph}{10pt}{0pt}{6pt}[0pt]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Comments

\newcommand{\js}[1]{ {\color{magenta} js:  #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%SVG images

\usepackage{svg}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%tikzcd
\usepackage{tikz-cd} 			
\usepackage{tikz}
\usetikzlibrary{arrows.meta}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Paragraph markers
%\newcommand{\paragraphMarker}[1]{ %{\color{gray} $\langle$#1$\rangle$}
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Lean formating
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{chngcntr}
\definecolor{keywordcolor}{rgb}{0.7, 0.1, 0.1}   % red
\definecolor{tacticcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4}   % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}      % green
\definecolor{attributecolor}{rgb}{0.7, 0.1, 0.1} % red

\def\lstlanguagefiles{lstlean.tex}
\lstset{
 	frame = lrtb,
 	rulecolor=\color{mycolor},
	language=lean,
	aboveskip = 5mm,
	belowskip = 5mm,
	captionpos=t
	}

\lstnewenvironment{code}[1][]%
{
   \noindent\newline
   \minipage{\linewidth}
   \vspace{0.5\baselineskip}
   \lstset{
 	frame = lrtb,
 	rulecolor=\color{mycolor},
 	escapeinside={/*!}{!*/},
	language=lean,
	aboveskip = 5mm,
	belowskip = 5mm,
	xleftmargin=2mm,
	xrightmargin=2mm,
	}
	}
{\endminipage\newline}
\lstnewenvironment{codeLong}[1][]%
{
   \lstset{
 	frame = lrtb,
 	rulecolor=\color{mycolor},
 	escapeinside={/*!}{!*/},
	language=lean,
	aboveskip = 5mm,
	belowskip = 5mm,
	xleftmargin=2mm,
	xrightmargin=2mm,
	}
	}
{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Links in code block
% put at top of code block using
% /*!\codeLink{...}!*/
\newcommand{\codeLink}[1]{
  \vspace{-0.5cm}\hfill\href{https://github.com/HEPLean/HepLean/blob/1b951994ae3d882242b02d23957ef1ee7fa05f3d/HepLean/#1}{(source)}
  }
  \newcommand{\codeBreakdownLink}[2]{
  \vspace{-0.5cm}\hfill\href{https://github.com/HEPLean/HepLean/blob/1b951994ae3d882242b02d23957ef1ee7fa05f3d/HepLean/#1}{(source)}
  (breakdown \ref{#2})
  }
 \newcommand{\textLink}[1]{\href{https://github.com/HEPLean/HepLean/blob/1b951994ae3d882242b02d23957ef1ee7fa05f3d/HepLean/#1}{source}}
 \newcommand{\textLinkB}[1]{\href{https://github.com/HEPLean/HepLean/blob/1b951994ae3d882242b02d23957ef1ee7fa05f3d/HepLean/#1}{(source)}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Syntax elab code block 
\usepackage[table]{xcolor}
\newcommand{\syntaxElab}[2]{ 
  \arrayrulecolor{mycolor}
  \begin{center}
    \begin{tabular}{|p{1.7in} | p{4in}|}
    \hline
    \hfill {#1} & {#2} \\
    \hline
    \end{tabular}
    \end{center}
  \arrayrulecolor{black}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Proof step 

\newcommand{\proofstep}[3]{
  \arrayrulecolor{mycolor}
\begin{center}
\begin{tabular}{|p{3in}| p{3in}|}
\hline
{#1
}\newline 
\hrule~\newline
#2
  & ~\newline
\makebox[3in]{%
#3}
  \\ \hline
\end{tabular}
\end{center}
\arrayrulecolor{black}
}

\newcommand{\tensorTree}[1]{
\begin{center}
  \fcolorbox{mycolor}{white}{%
#1}
\end{center}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Math commands 
\newcommand{\Rep}[2]{\mathrm{Rep} \; #1 \; #2}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Title, author, date
\title{Index notation in Lean 4}
\author{Joseph Tooby-Smith \\ \textit{Reykjavik University, Reykjavik, Iceland}}
\date{\today}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\counterwithin{lstlisting}{section}
\maketitle
\vspace{-1cm}
\begin{abstract}
The physics community relies on index notation to effectively manipulate types of tensors.
This paper introduces the first formally verified implementation of index notation in the
interactive theorem prover Lean 4. By integrating index notation into Lean, we bridge the gap between 
traditional physics notation and formal verification tools, 
making it more accessible for physicists to write and prove results within Lean.
In the background, our implementation leverages a novel application of category theory.
\end{abstract}

{\color{mycolor} The file you are currently reading is a draft. There will 
be typos, mistakes, sentences that don't make sense, notation that is not defined etc.}
\section{Introduction}

In previous work~\cite{HepLean}, the author initiated the digitalization (or formalization) 
of high energy physics 
results using the interactive theorem prover Lean 4 in a project called HepLean. 
Lean is a
programming language with syntax resembling traditional pen-and-paper mathematics. 
Users can write definitions, theorems, and proofs in Lean,
which are then automatically checked for correctness using dependent-type theory.
The HepLean project is driven by four primary motivations: to facilitate easier look-up of results
 through a linear storage of information; to support the creation and proof of new results using 
 automated tactics and AI tools; to facilitate correctness checking of result in high energy physics; 
 and to introduce new pedogocial methods for high-energy physics and computer science.

HepLean is part of a broader movement of projects
to formalize parts, or all, of 
mathematics and science. The largest of these projects is Mathlib~\cite{mathlib}, which aims to formalize
mathematics. Indeed, HepLean uses many results from Mathlib, and is built downstream thereof.
Other projects in mathematics include the ongoing effort led by Kevin Buzzard to formalize the proof of Fermat's
Last Theorem into Lean~\cite{FLT}. 
In the realm of the sciences, the paper~\cite{josephson} looks at absorption theory, thermodynamics, and kinematics in Lean, 
whilst the package SciLean~\cite{SciLean}, is a push in the direction of scientific computing within Lean. 

Physicists rely heavily on specialized notation to express mathematical concepts succinctly. 
Among these index notation is particularly prevalent,
 as it provides a compact and readable way to represent specific types of tensors and operations
 between them. Such tensors form a backbone of modern physics. 

Having a way to use index notation in Lean is crucial for the digitalisation of 
results from high energy physics. 
As well as, making results from high energy physics easier to write and prove in Lean, 
it will make the syntax more familiar to high energy physicists. 
Such an implementation is the subject of this paper. 
It is a challenge because, we need an implementation that is nice and flexiable to use, 
but which is also formally well-defined and rigourous. 
We hope that the implementation presented here will
not only enhances usability of Lean but also promotes the adoption of formal methods in the 
physics community.

As a taster of what is to come, in our implementation the result regarding Pauli matrices 
that $\sigma^{\nu \alpha \dot \beta}\sigma_\nu{ \alpha' \dot \beta'} = 2 \epsilon^{\alpha \alpha'}\epsilon^{\beta \beta'}$ 
is written in Lean as follows
\begin{code}
{pauliCo | ν α β ⊗ pauliContr | ν α' β' = 2 •ₜ εL | α α' ⊗ εR | β β'}ᵀ
\end{code}
Lean will correctly interpret this result as a tensor expression with the correct contraction of indices 
and permutation of indices between the sides of the expression.

Previous implementations of index notation have been made in programming languages like Haskell 
\cite{haskellPaper}. However, the programs they appear in do not
 provide the formal verification capabilities inherent in Lean. 
 The formal verification requirement of Lean introduces unique challenges in implementing index 
 notation, necessitating (what we believe is) a novel solution.

In Section~\ref{sec:Implementation} of this paper, we will discuss the details of our implementation. 
In Section~\ref{sec:examples} we will give two examples of theorems and proofs using index notation.
The first of these examples involves a lemma regarding the contraction of indices of symmetric and anti-symmetric tensors. 
The second involves examples related to the Pauli matrices and bi-spinors. 
We finish this paper in Section~\ref{sec:future} by discussing potential future work related to this project.

\section{Implementation of index notation into Lean 4}\label{sec:Implementation}

\begin{figure}
  \centering
  \begin{tikzpicture}[
    thick,
    >=Stealth,
    box/.style={rectangle, draw, minimum height=1cm, minimum width=2.5cm, align=center},
    dashedbox/.style={rectangle, draw, dashed, minimum height=1cm, minimum width=2.5cm, align=center}
  ]
  
  % Nodes
  \node[dashedbox] (syntax) at (0,0) {Syntax};
  \node[box] (tensorTree) at (5,0) {Tensor Tree};
  \node[box] (tensor) at (10,0) {Tensor};
  
  % Edges
  \draw[->, dashed] (syntax) -- node[above] {Elab} (tensorTree);
  \draw[->] (tensorTree) -- node[above] {Cat theory} (tensor);
  
  \end{tikzpicture}
  \caption{Overview of the implementation of index notation in Lean. The 
  solid lines represent formally verified parts of the implementation.}
  \label{fig:overviewFlow}
\end{figure}

Our implementation of index notation can be thought of as three different representations of tensor 
expressions and maps between them. This is illustrated in Figure~\ref{fig:overviewFlow}.

The first representation is \emph{syntax}. This can (roughly) be thought of as the informal string
that represents the tensor expression. It is what the user interacts with when 
writing results in Lean, and what appears in raw Lean files. The code snippet above, 
for Pauli matrices is an example of syntax. 

The second representation of a tensor expression is a \emph{tensor tree}. This representaiton is 
mathematically formal, but easy to use and manipulate. 
It is a structured tree which has different types 
of nodes for each of the main operations that one can perform on tensors.

The process of going from syntax to a tensor tree is done via an elaborator 
which follows a number of (informally defined) rules.

The third and final representation is a bona-fide \emph{tensor}. This representation 
is the mathematical object that we are actually intrested in. However, in going to this representation
we lose the structure of the tensor expression itself, making it somewhat difficult to work with. 

The process of going from a tensor tree to a tensor involves properties from the symmetric monoidal 
category of representations. 

Before we discuss these processes in more detail we do some set-up by defining formally a 
`tensor species'. 

\subsection{Tensor Species}

A tensor species is a formalization of the data needed to define e.g., complex Lorentz tensors, 
real Lorentz tensors or Einstein tensors. The word `species' is a nod to `graphical species'
defining in \js{...}, from which our construction is inspired.

We will start by giving the complete definition of a tensor species in Lean, and then 
disect this definition, discussing each of the components in turn. 

In Lean a tensor species is defined as follows:
\begin{codeLong}
/-- The sturcture of a type of tensors e.g. Lorentz tensors, Einstien tensors,
complex Lorentz tensors. -/
structure TensorSpecies where
  /-- The commutative ring  over which we want to consider the tensors to live in,
    usually `ℝ` or `ℂ`. -/
  k : Type
  /-- An instance of `k` as a commutative ring. -/
  k_commRing : CommRing k
  /-- The symmetry group acting on these tensor e.g. the Lorentz group or SL(2,ℂ). -/
  G : Type
  /-- An instance of `G` as a group. -/
  G_group : Group G
  /-- The colors of indices e.g. up or down. -/
  C : Type
  /-- A functor from `C` to `Rep k G` giving our building block representations.
    Equivalently a function `C → Re k G`. -/
  FDiscrete : Discrete C ⥤ Rep k G
  /-- A specification of the dimension of each color in C. This will be used for explicit
    evaluation of tensors. -/
  repDim : C → ℕ
  /-- repDim is not zero for any color. This allows casting of `ℕ` to `Fin (S.repDim c)`. -/
  repDim_neZero (c : C) : NeZero (repDim c)
  /-- A basis for each Module, determined by the evaluation map. -/
  basis : (c : C) → Basis (Fin (repDim c)) k (FDiscrete.obj (Discrete.mk c)).V
  /-- A map from `C` to `C`. An involution. -/
  τ : C → C
  /-- The condition that `τ` is an involution. -/
  τ_involution : Function.Involutive τ
  /-- The natural transformation describing contraction. -/
  contr : OverColor.Discrete.pairτ FDiscrete τ ⟶ 𝟙_ (Discrete C ⥤ Rep k G)
  /-- Contraction is symmetric with respect to duals. -/
  contr_tmul_symm (c : C) (x : FDiscrete.obj (Discrete.mk c))
      (y : FDiscrete.obj (Discrete.mk (τ c))) :
    (contr.app (Discrete.mk c)).hom (x ⊗ₜ[k] y) = (contr.app (Discrete.mk (τ c))).hom
    (y ⊗ₜ (FDiscrete.map (Discrete.eqToHom (τ_involution c).symm)).hom x)
  /-- The natural transformation describing the unit. -/
  unit : 𝟙_ (Discrete C ⥤ Rep k G) ⟶ OverColor.Discrete.τPair FDiscrete τ
  /-- The unit is symmetric. -/
  unit_symm (c : C) :
    ((unit.app (Discrete.mk c)).hom (1 : k)) =
    ((FDiscrete.obj (Discrete.mk (τ (c)))) ◁
      (FDiscrete.map (Discrete.eqToHom (τ_involution c)))).hom
    ((β_ (FDiscrete.obj (Discrete.mk (τ (τ c)))) (FDiscrete.obj (Discrete.mk (τ (c))))).hom.hom
    ((unit.app (Discrete.mk (τ c))).hom (1 : k)))
  /-- Contraction with unit leaves invariant. -/
  contr_unit (c : C) (x : FDiscrete.obj (Discrete.mk (c))) :
    (λ_ (FDiscrete.obj (Discrete.mk (c)))).hom.hom
    (((contr.app (Discrete.mk c)) ▷ (FDiscrete.obj (Discrete.mk (c)))).hom
    ((α_ _ _ (FDiscrete.obj (Discrete.mk (c)))).inv.hom
    (x ⊗ₜ[k] (unit.app (Discrete.mk c)).hom (1 : k)))) = x
  /-- The natural transformation describing the metric. -/
  metric : 𝟙_ (Discrete C ⥤ Rep k G) ⟶ OverColor.Discrete.pair FDiscrete
  /-- On contracting metrics we get back the unit. -/
  contr_metric (c : C) :
    (β_ (FDiscrete.obj (Discrete.mk c)) (FDiscrete.obj (Discrete.mk (τ c)))).hom.hom
    (((FDiscrete.obj (Discrete.mk c)) ◁ (λ_ (FDiscrete.obj (Discrete.mk (τ c)))).hom).hom
    (((FDiscrete.obj (Discrete.mk c)) ◁ ((contr.app (Discrete.mk c)) ▷
    (FDiscrete.obj (Discrete.mk (τ c))))).hom
    (((FDiscrete.obj (Discrete.mk c)) ◁ (α_ (FDiscrete.obj (Discrete.mk (c)))
      (FDiscrete.obj (Discrete.mk (τ c))) (FDiscrete.obj (Discrete.mk (τ c)))).inv).hom
    ((α_ (FDiscrete.obj (Discrete.mk (c))) (FDiscrete.obj (Discrete.mk (c)))
      (FDiscrete.obj (Discrete.mk (τ c)) ⊗ FDiscrete.obj (Discrete.mk (τ c)))).hom.hom
    ((metric.app (Discrete.mk c)).hom (1 : k) ⊗ₜ[k]
      (metric.app (Discrete.mk (τ c))).hom (1 : k))))))
    = (unit.app (Discrete.mk c)).hom (1 : k)
\end{codeLong}

Let us go through this definition piece by piece.
Firstly \lstinline|k| is a type, has the instance \lstinline|k_commRing| of a commuative ring. 
It represents the ring (or field) that our tensors are defined over. For complex Lorentz tensors, 
this is naturally, the field of complex numbers. 

The type \lstinline|G| has the instance of a group \lstinline|G_group|. It represents 
the group which acts on our tensors. For complex Lorentz tensors, this is the group 
$SL(2, \mathbb{C})$, whilst for real Lorentz tensors this is the Lorentz group. 

The type \lstinline|C| is a type of colors.
For complex Lorentz tensors, there are six colors forming the type 
\begin{code}
inductive Color
  | upL : Color
  | downL : Color
  | upR : Color
  | downR : Color
  | up : Color
  | down : Color
\end{code}
Colors can be thought of as labels for each of the building 
block representations making up the tensor species.  This is made formal by the functor 
\lstinline|FDiscrete|, which assigns to each color a representation of $G$ over $k$.
In what follows we will use $F_D$ to denote this functor.
For complex Lorentz tensors, this is defined as follows:
\begin{code}
FDiscrete := Discrete.functor fun c =>
  match c with
  | Color.upL => Fermion.leftHanded
  | Color.downL => Fermion.altLeftHanded
  | Color.upR => Fermion.rightHanded
  | Color.downR => Fermion.altRightHanded
  | Color.up => Lorentz.complexContr
  | Color.down => Lorentz.complexCo
\end{code}
The representations defined here are: 
\begin{itemize}
  \item The representation of left-handed Weyl fermions, 
    denoted in Lean as \lstinline|Fermion.leftHanded|, and corresponding to the 
    representation of $SL(2, \mathbb{C})$ taking $v \mapsto M v$ for $M \in SL(2, \mathbb{C})$.
  \item The representation of `alternative' left-handed Weyl fermions, 
    denoted in Lean as \lstinline|Fermion.altLeftHanded|, and corresponding to the 
    representation of $SL(2, \mathbb{C})$ taking $v \mapsto M^{-1 T} v$ for $M \in SL(2, \mathbb{C})$.
  \item The representation of right-handed Weyl fermions, 
    denoted in Lean as \lstinline|Fermion.rightHanded|, and corresponding to the 
    representation of $SL(2, \mathbb{C})$ taking $v \mapsto M^\star v$ for $M \in SL(2, \mathbb{C})$.
  \item The representation of `alternative' right-handed Weyl fermions,
    denoted in Lean as \lstinline|Fermion.altRightHanded|, and corresponding to the 
    representation of $SL(2, \mathbb{C})$ taking $v \mapsto M^{-1 \dagger} v$ for $M \in SL(2, \mathbb{C})$.
  \item The representation of contravariant Lorentz tensors, 
    denoted in Lean as \lstinline|Lorentz.complexContr|, and corresponding to the 
    representation of $SL(2, \mathbb{C})$ induced by the homomorphism of $SL(2, \mathbb{C})$ into 
    the Lorentz group and the contravariant action of the Lorentz group on four-vectors.
  \item The representation of covariant Lorentz tensors,
     denoted in Lean as \lstinline|Lorentz.complexCo|, and corresponding to the 
    representation of $SL(2, \mathbb{C})$ induced by the homomorphism of $SL(2, \mathbb{C})$ into 
    the Lorentz group and the covariant action of the Lorentz group on four-vectors.
\end{itemize}
As an example, the representation of left-handed Weyl fermions  \lstinline|Fermion.leftHanded|
is defined in Lean as follows:
\begin{codeLong}
/-- The vector space ℂ^2 carrying the fundamental representation of SL(2,C).
  In index notation corresponds to a Weyl fermion with indices ψ^a. -/
def leftHanded : Rep ℂ SL(2,ℂ) := Rep.of {
  /- The function from SL(2,ℂ) to endomorphisms of LeftHandedModule 
    (which corresponds to the vector space ℂ^2). -/
  toFun := fun M => {
    /- Start of the definiton of the linear map. -/
    /- The function underlying the linear map. Defined as the dot product. -/
    toFun := fun (ψ : LeftHandedModule) =>
      LeftHandedModule.toFin2ℂEquiv.symm (M.1 *ᵥ ψ.toFin2ℂ),
    /- Proof that the function is linear with respect to addition. -/
    map_add' := by
      intro ψ ψ'
      simp [mulVec_add]
    /- Proof that the function is linear with respect to scalar multiplication. -/
    map_smul' := by
      intro r ψ
      simp [mulVec_smul]
    /- End of the definiton of the linear map. -/}
  /- Proof that (the outer) toFun gives the identity map on the identity of SL(2,ℂ). -/
  map_one' := by
    ext i
    simp
  /- Proof that the action of the product of two elements is 
    the product of the actions of the elements. -/
  map_mul' := fun M N => by
    simp only [SpecialLinearGroup.coe_mul]
    ext1 x
    simp only [LinearMap.coe_mk, AddHom.coe_mk, LinearMap.mul_apply, LinearEquiv.apply_symm_apply,
      mulVec_mulVec]}
\end{codeLong} 
We have added some explainatary comments to this code, not seen in the actual Lean code, to give 
the reader an idea of what each part does. 

The map \lstinline|repDim| assigns to each color a natural number, which corresponds 
to the dimension of the representation associated to that color. The condition is placed on 
the representations that they are non-empty, i.e., that the dimension is not equal to zero \lstinline|repDim_neZero|.  
The map \lstinline|basis| gives a basis indexed by \lstinline|(Fin (repDim c))| (numbers from 0 to $\mathrm{repDim}\; c -1 $)  of each representation for each $c \in C$.  
We will use this basis in the definition of evaluation of tensor indices. 

To each color the map \lstinline|τ|, which is an involution via \lstinline|τ_involution|, defines 
a dual color. The dual of a color is that which it can be contracted with. So, for complex Lorentz tensors 
the map \lstinline|τ| is given by 
\begin{code} 
τ := fun c =>
  match c with
  | Color.upL => Color.downL
  | Color.downL => Color.upL
  | Color.upR => Color.downR
  | Color.downR => Color.upR
  | Color.up => Color.down
  | Color.down => Color.up
\end{code}

The contraction is defined by \lstinline|contr|, which is a natural transformation from the functor 
$F_D(\_) \otimes F_D (\tau (\_))$, to the functor $\mathbbm{1}$ takes every object in $C$ to the trivial representation $k$. 
This natural transformation is simply the assignment to each color $c$ a map from 
$F_D(c) \otimes F_D (\tau(c))$ to $k$ which is equivariant with respect to the group action. 
This contraction cannot be defined arbitarily, but must satisfy the symmetry condition \lstinline|contr_tmul_symm|, 
which correpsonds to the diagram 
\begin{equation}
\begin{tikzcd}
  F_D(c) \otimes F_D(\tau c) \arrow[r, "{\beta}"] \arrow[d, "{\mathcal{C}(c)}", swap] & F_D(\tau c) \otimes F_D (c) \arrow[d, "\mathbbm{1} \otimes F_D \tau_c"] \\
  \mathbb{I} & F_D(\tau c) \otimes F_D (\tau \tau c) \arrow[l, "{\mathcal{C}(\tau(c))}", ] 
\end{tikzcd}
\end{equation}
commuting, where $\beta$ is the braiding of the symmetric monoidal category, and $\tau_c$ is the isomorphism
in $C$ between $\tau(\tau(c))$ and $c$, which exists since $\tau$ is an involution.

Along with the contraction we define the \lstinline|unit|, along with its own symmetry condition 
\lstinline|unit_symm|. The unit is a natural transformation from the functor  $\mathbbm{1}$ to 
$F_D(\tau(\_)) \otimes F_D (\_)$. This is the assignment to each color $c$ an object of 
$F_D(\tau(c)) \otimes F_D (c)$ which is invariant with respect to the group action. 
The symmetry condition \lstinline|unit_symm| is represented by the diagram 
\begin{equation} 
  \begin{tikzcd}
    \mathbb{I} \arrow[r, "{\delta(c)}"] \arrow[d, "{\delta(\tau(c))}"] & F_D(\tau c) \otimes F_D(c) \\
    F_D(\tau \tau c) \otimes F_D(\tau c) \arrow[r, "{\beta}"] & F_D(\tau c) \otimes F_D(\tau \tau c) \arrow[u, "{\mathbbm{1} \otimes F_D \tau_c}"]
  \end{tikzcd}
\end{equation} 
The unit is actually a unit in the sense that contraction with it does nothing. This is made formal with the condition 
\lstinline|contr_unit|, which is corresponds to the diagram 
\begin{equation}
  \begin{tikzcd}
    F_D(c) \arrow[r, "{\rho^{-1}}"] &  F_D(c) \otimes \mathbb{I} \arrow[r, "{\mathbbm{1}\otimes \delta(c)}"] & F_D(c) \otimes (F_D (\tau c) \otimes F_D(c)) \arrow[d, "{\alpha^{-1}}"] \\
    \mathbb{I} \otimes F_D(c) \arrow[u, "{\lambda}"] &   &(F_D(c) \otimes F_D(\tau c)) \otimes F_D(c) \arrow[ll, "{\mathcal{C}(c)\otimes \mathbbm{1}}"] 
\end{tikzcd}
\end{equation}
where $\rho$ is the right-unitor, $\lambda$ the left-unitor, and $\alpha$ is the associator. 

The final part of the definition of a tensor species is the definition of the metric, \lstinline|metric| 
and it's interaction with the contraction and unit \lstinline|contr_metric|. 
The metric is a natural transformation from the functor $\mathbbm{1}$
to the functor $F_D(\_) \otimes F_D (\_)$. It thus represents the assignement to each color $c$ an object of
$F_D(c) \otimes F_D (c)$ which is invariant with respect to the group action.
The metric can be used to change an index into a dual index. The condition \lstinline|contr_metric|
corresponds to the diagram 
\begin{equation}
  \begin{tikzcd}
    \mathbb{I} \arrow[r, "{\delta(c)}"] \arrow[d, "{\eta(c)\otimes \eta(\tau(c))}"] & F_D(\tau c) \otimes F_D (c) \\ 
    (F_D c \otimes F_d c) \otimes (F_D (\tau c) \otimes F_D (\tau c) ) \arrow [d]  & F_D (c) \otimes F_D(\tau c) \arrow[u, "{\beta}"] \\ 
    F_D c \otimes (F_d c \otimes (F_D (\tau c) \otimes F_D (\tau c) )) \arrow [r] &  F_D c \otimes ((F_d c \otimes F_D (\tau c)) \otimes F_D (\tau c) ) \arrow[u, "{\mathbbm{1} \otimes(\mathcal{C}(c) \otimes \mathbbm{1})}"]
  \end{tikzcd}
\end{equation}

\subsection{Tensors} 

Given any type $C$, which we will think of as a type of colors, we can define 
the category $\mathrm{T}_{/C}^\times$ as follows. Objects are functions 
$f : X \to C$ for some type $X$. A morphism from $f : X \to C$ to $g : Y \to C$ is a bijection
$\phi : X \to Y$ such that $f = g \circ \phi$. This category is equivalent to the core of the
category of types sliced over $C$, which explains the origin of the notation. 
In Lean we denote this category as \lstinline|OverColor C|, although we will use the 
shorter notation $\mathrm{T}_{/C}^\times$ here when we can.

The category $\mathrm{T}_{/C}^\times$ is not any old category, it carries a symmetric monoidal structure, 
which we will denote $\otimes$. The structure such that $f \otimes g$ for objects $f$ and $g$ 
is the map $X \oplus Y \to C$ where $\oplus$ denotes the disjoint union of types. 

The functor $F_D$ defined above, can be lifted to a symmetric monoidal functor $F$ from 
$\mathrm{T}_{/C}^\times$ to $\Rep k G$. This functor takes $f : X \to C$ to the tensor product
$\bigotimes_{x \in X} F_D(f(x))$ and morphisms to the linear maps of representations corresponding to
reindexings of tensor products. This construction is general, and functorial. In otherwords, 
there is a functor 
\begin{equation}
  \mathrm{lift} : \mathrm{Fun}(C, \mathrm{Rep} k G) \Rightarrow
  \mathrm{SymmMonFun}(\mathrm{T}_{/C}^\times, \mathrm{Rep} k G)
\end{equation} 
In Lean we define this functor, along with the corresponding lift of $F_D$, $F$.

We can think of an object $f : X \to C$ of $\mathrm{T}_{/C}^\times$ as a type of indices $X$, and a specification 
of what repreesntation each index is associated to. The representation $F(f)$ is 
then the tensor product of each of these representations, so that vectors $v \in F(f)$ can be thought of as 
tensors with indices indexed by $X$ of color $C$ (e.g. `up' or `down'). 

With this in mind, we define a general tensor of a given species as a vector in the representation $F(f)$ 
for some $f$ in $\mathrm{T}_{/C}^\times$.

In physics, we typically focus on objects $f : X \to C$ in $\mathrm{T}_{/C}^\times$ where $X$ is a 
finite type of the form $\mathrm{Fin}\, n$ for some $n$. Here, $\mathrm{Fin}\, n$ represents the 
type of natural numbers less than $n$, i.e., $\{0, 1, \dots, n-1\}$. When appropraite in what follows, 
we will restrict to these objects.

In Lean for a map of types \lstinline|f : X \to C|, what we have been writing as $F(f)$ is written 
as \lstinline|S.F.obj (OverColor.mk f)|. The object \lstinline|S| is the tensor species, which we will
define shortly. The \lstinline|OverColor.mk| tells lean that the function \lstinline|f| should 
be considered as an object of \lstinline|OverColor C|, not just as an object of type \lstinline|X -> C|. \js{fix arrows here}

\subsection{Tensor Trees and their map to tensors}

Tensor trees are tress with a node for each of the basic operations one can perform on a tensor. 
Namely, tensor trees have nodes for addition of tensors, permutation of tensor indices, negation of tensors, 
  scalar multiplication of tensors, group action on a tensor, tensor product of tensors, contraction of tensor indices,
  and evaluation of tensor indices.
They also have nodes for tensors themselves.

Given a species \lstinline|S|, we have a type of tensor tree for each map of the form
\lstinline|c : Fin n → S.C| in \lstinline|OverColor S.C|. 
This restriction to \lstinline|Fin n| is done for convience.

Tensor trees are defined inductively through a number of constructors: 
\begin{code}
inductive TensorTree (S : TensorSpecies) : {n : ℕ} → (Fin n → S.C) → Type where
  /-- A general tensor node. -/
  | tensorNode {n : ℕ} {c : Fin n → S.C} (T : S.F.obj (OverColor.mk c)) : TensorTree S c
  /-- A node correpsonding to the scalar multiple of a tensor by a element of the field. -/
  | smul {n : ℕ} {c : Fin n → S.C} : S.k → TensorTree S c → TensorTree S c
  /-- A node corresponding to negation of a tensor. -/
  | neg {n : ℕ} {c : Fin n → S.C} : TensorTree S c → TensorTree S c
  /-- A node corresponding to the addition of two tensors. -/
  | add {n : ℕ} {c : Fin n → S.C} : TensorTree S c → TensorTree S c → TensorTree S c
  /-- A node correpsonding to the action of a group element on a tensor. -/
  | action {n : ℕ} {c : Fin n → S.C} : S.G → TensorTree S c → TensorTree S c
  /-- A node corresponding to the permutation of indices of a tensor. -/
  | perm {n m : ℕ} {c : Fin n → S.C} {c1 : Fin m → S.C}
      (σ : (OverColor.mk c) ⟶ (OverColor.mk c1)) (t : TensorTree S c) : TensorTree S c1
  /-- A node corresponding to the product of two tensors. -/
  | prod {n m : ℕ} {c : Fin n → S.C} {c1 : Fin m → S.C}
    (t : TensorTree S c) (t1 : TensorTree S c1) : TensorTree S (Sum.elim c c1 ∘ finSumFinEquiv.symm)
  /-- A node corresponding to the contraction of indices of a tensor. -/
  | contr {n : ℕ} {c : Fin n.succ.succ → S.C} : (i : Fin n.succ.succ) →
    (j : Fin n.succ) → (h : c (i.succAbove j) = S.τ (c i)) → TensorTree S c →
    TensorTree S (c ∘ Fin.succAbove i ∘ Fin.succAbove j)
  /-- A node corresponding to the evaluation of an index of a tensor. -/
  | eval {n : ℕ} {c : Fin n.succ → S.C} : (i : Fin n.succ) → (x : ℕ) → TensorTree S c →
    TensorTree S (c ∘ Fin.succAbove i)
\end{code}
Each constructor here, e.g. \lstinline|tensorNode|, \lstinline|smul|, \lstinline|neg|, etc., can 
be thought of a forming a different type of node in a tensor tree.

Since the interpretation of each of the constructors is down to how we turn them into a tensor,
we dicuss this before dicussing each of the constructors in turn. The process 
of going from a tensor tree to a tensor is proscribed by a function
\lstinline|TensorTree S c  → S.F.obj (OverColor.mk c)|, which is defined recursively as follows: 
\begin{code}
/-- The underlying tensor a tensor tree corresponds to. -/
def tensor {n : ℕ} {c : Fin n → S.C} : TensorTree S c → S.F.obj (OverColor.mk c) := fun
  | tensorNode t => t
  | smul a t => a • t.tensor
  | neg t => - t.tensor
  | add t1 t2 => t1.tensor + t2.tensor
  | action g t => (S.F.obj (OverColor.mk _)).ρ g t.tensor
  | perm σ t => (S.F.map σ).hom t.tensor
  | prod t1 t2 => (S.F.map (OverColor.equivToIso finSumFinEquiv).hom).hom
    ((S.F.μ _ _).hom (t1.tensor ⊗ₜ t2.tensor))
  | contr i j h t => (S.contrMap _ i j h).hom t.tensor
  | eval i e t => (S.evalMap i (Fin.ofNat' _ e)) t.tensor
\end{code}

Let us now dicuss each of the constructors in turn, after which we will give some examples 
tensor trees.  

\paragraph{tensorNode:} The constructor \lstinline|tensorNode| based on \lstinline|c|
creates a tensor tree from a tensor \lstinline|t| in \lstinline|S.F.obj (OverColor.mk c)|. 
This tensor tree consists of a single node that directly represents the tensor. 
Since all other tensor tree constructors require an existing tensor tree as input, 
\lstinline|tensorNode| serves as the foundational base case for building more complex trees. 
Diagramatically, such a tree is 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|t|};
  \end{tikzpicture} 
}
Naturally, the tensor associated with this node is exactly the tensor provided during construction.

\paragraph{smul:} The constructor smul takes a scalar \lstinline|a| and an existing tensor tree 
\lstinline|t| based on \lstinline|c| and constructs a new tensor tree also based on \lstinline|c|. Conceptually, this new tree has a root node labeled 
\lstinline|smul a|, with the tensor tree 
\lstinline|t| as its child. Diagramatically, such a tree is 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|smul a|};
    \node (B) at (0,-1) {\lstinline|t|};
    \draw[->] (A) -- (B);
  \end{tikzpicture} 
}
The tensor associated with this new tree is obtained by multiplying the tensor associated with 
\lstinline|t| by the scalar \lstinline|a|.

\paragraph{neg:} The constructor \lstinline|neg| takes an existing tensor tree \lstinline|t|
 based on \lstinline|c| and constructs a new tensor tree also based on \lstinline|c|.
This new tree has a root node labeled \lstinline|neg|, with the tensor tree \lstinline|t| as its child.
Diagramatically, we have 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|neg|};
    \node (B) at (0,-1) {\lstinline|t|};
    \draw[->] (A) -- (B);
  \end{tikzpicture} 
}
The tensor associated with this new tree is obtained by negating the tensor associated with \lstinline|t|.


\paragraph{add:} 
The constructor \lstinline|add| takes two existing tensor trees \lstinline|t1| and \lstinline|t2|, based on the same \lstinline|c|, and 
constructs a new tensor tree. This new tree has a root node labeled \lstinline|add|, with the tensor trees \lstinline|t1| and \lstinline|t2| as its children.
Diagramatically, this corresponds to 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|add|};
    \node (B) at (-1,-1) {\lstinline|t1|};
    \node (C) at (1,-1) {\lstinline|t2|};
    \draw[->] (A) -- (B);
    \draw[->] (A) -- (C);
  \end{tikzpicture} 
}
The tensor associated with this new tree is obtained by adding the tensors associated with \lstinline|t1| and \lstinline|t2|.

\paragraph{action:}
The constructor \lstinline|action| takes a group element \lstinline|g| of \lstinline|S.G|, an existing tensor tree \lstinline|t| based on \lstinline|c|, and constructs a new tensor tree also based on \lstinline|c|.
This new tree has a root node labeled \lstinline|action g|, with the tensor tree \lstinline|t| as its child.
Diagramatically, 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|action g|};
    \node (B) at (0,-1) {\lstinline|t|};
    \draw[->] (A) -- (B);
  \end{tikzpicture} 
}
The tensor associated with this new tree is obtained by acting on the tensor associated with \lstinline|t| with the group element \lstinline|g|.

\paragraph{perm:}
The constructor \lstinline|perm| takes a morphism \lstinline|σ| from \lstinline|c| to \lstinline|c1| in \lstinline|OverColor S.C| and 
  an existing tensor tree \lstinline|t| based on \lstinline|c|, and constructs a new tensor tree based on \lstinline|c1|.
This new tree has a root node labeled \lstinline|perm σ|, with the tensor tree \lstinline|t| as its child.
Diagramatically, this is given by 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|perm σ|};
    \node (B) at (0,-1) {\lstinline|t|};
    \draw[->] (A) -- (B);
  \end{tikzpicture} 
}
The tensor associated with this new tree is obtained by  applying the image of the morphism \lstinline|σ| under the functor \lstinline|S.F|
to the tensor associated with \lstinline|t|.

\paragraph{prod:}
The constructor \lstinline|prod| takes two existing tensor trees \lstinline|t| based on \lstinline|c| and \lstinline|t1| based on \lstinline|c1| and constructs a new tensor tree
based on \lstinline|Sum.elim c c1 ∘ finSumFinEquiv.symm| which is the map from \lstinline|Fin (n + n1)| 
acting via \lstinline|c i| on $i=0, \ldots, n-1$ and via \lstinline|c1 (i - n)| on $i = n, \ldots, n + n1 -1$.
This new tree has a root node labeled \lstinline|prod|, with the tensor trees \lstinline|t| and \lstinline|t1| as its children.
Diagramatically, this is given by
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|prod|};
    \node (B) at (-1,-1) {\lstinline|t|};
    \node (C) at (1,-1) {\lstinline|t1|};
    \draw[->] (A) -- (B);
    \draw[->] (A) -- (C);
  \end{tikzpicture} 
}
The tensor associated with this new tree is obtained by taking the tensor product of the tensors associated with \lstinline|t| and \lstinline|t1|, 
giving a vector in \lstinline|S.F.obj (OverColor.mk c) ⊗ S.F.obj (OverColor.mk c1)|, using the tensorate of \lstinline|S.F| to map this vector into 
a vector in \lstinline|S.F.obj (OverColor.mk c ⊗ OverColor.mk c1)|, and finally using an isomorphism between \lstinline|OverColor.mk c ⊗ OverColor.mk c1| and 
\lstinline|OverColor.mk (Sum.elim c c1 ∘ finSumFinEquiv.symm)| to map this vector into
 \lstinline|S.F.obj (OverColor.mk (Sum.elim c c1 ∘ finSumFinEquiv.symm))|.

\paragraph{contr:}
The constructor \lstinline|contr| firstly, takes an existing tensor tree \lstinline|t| based on a 
\lstinline|c : Fin n.succ.succ -> S.C|. Here \lstinline|n.succ.succ| is $n + 1 + 1$ with \lstinline|succ| meaning 
the succesor of a natural number. 
It also takes,
an \lstinline|i| of type \lstinline|Fin n.succ.succ|, \lstinline|j| of type \lstinline|Fin n.succ|
and a proof that \lstinline|c (i.succAbove j) = S.τ (c i)|, where \lstinline|i.succAbove| is the map from \lstinline|Fin n.succ| to \lstinline|Fin n.succ.succ| with a hole at \lstinline|i|. 
The proof says that the color of the index \lstinline|i.succAbove j| is the dual of the color of the index \lstinline|i|, and thus that these 
two indices can be contracted.
Note that we use a \lstinline|j| in \lstinline|Fin n.succ| and \lstinline|i.succAbove j| as the index to be contracted, instead 
of another index in  \lstinline|Fin n.succ.succ| to ensure the two indices to be contracted are not the same. 
The constructor outputs a new tensor tree based on \lstinline|c ∘ i.succAbove ∘ j.succAbove|. 
This new tree has a root node labeled \lstinline|contr i j|, with the tensor tree \lstinline|t| as its child.
Diagramatically, 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|contr i j|};
    \node (B) at (0,-1) {\lstinline|t|};
    \draw[->] (A) -- (B);
  \end{tikzpicture} 
}
The tensor associated with the new tensor tree is construced as follows. 
We start with a tensor in \lstinline|S.F.obj (OverColor.mk c)|.
This is mapped into a vector in \lstinline|(S.FDiscrete.obj (c i) ⊗ S.FDiscrete.obj (S.τ (c i))) ⊗ S.F.obj (OverColor.mk (c ∘ Fin.succAbove i ∘ Fin.succAbove j))| via an equivalence from 
\lstinline|S.F.obj (OverColor.mk c)|. The equivalence is constructed using an equivalence 
in \lstinline|OverColor C| to extract \lstinline|i| and \lstinline|i.succAbove j| from \lstinline|c|,
then using the tensorate of \lstinline|S.F|, and the fact that \lstinline|c (i.succAbove j) = S.τ (c i)|. 
Using the contraction for \lstinline|c i|, we then get a vector in 
\lstinline|𝟙 ⊗ S.F.obj (OverColor.mk (c ∘ Fin.succAbove i ∘ Fin.succAbove j))| which is then 
mapped to a tensor in \lstinline|S.F.obj (OverColor.mk (c ∘ Fin.succAbove i ∘ Fin.succAbove j))| 
using the left-unitor of \lstinline|Rep S.G S.k|.
\js{Relate this back to the tensor construction.}

\paragraph{eval:}
The final constructor \lstinline|eval| takes an existing tensor tree \lstinline|t| based on a \lstinline|c : Fin n.succ -> S.C|,
an \lstinline|i| of type \lstinline|Fin n.succ|, and a natural number $x$.  
The constructor outputs a new tensor tree based on \lstinline|c ∘ Fin.succAbove i|.
This new tree has a root node labeled \lstinline|eval i x|, with the tensor tree \lstinline|t| as its child.
Diagramatically, this corresponds to 
\tensorTree{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {\lstinline|eval i x|};
    \node (B) at (0,-1) {\lstinline|t|};
    \draw[->] (A) -- (B);
  \end{tikzpicture} 
}
The tensor associated with the new tensor tree is constructed as follows.
We start with a tensor in \lstinline|S.F.obj (OverColor.mk c)|.
This is mapped into a vector in \lstinline|S.FDiscrete.obj (c i) ⊗ S.F.obj (OverColor.mk (c ∘ Fin.succAbove i))| via an equivalence from
\lstinline|S.F.obj (OverColor.mk c)|. The equivalence is constructed using an equivalence
in \lstinline|OverColor C| to extract \lstinline|i| from \lstinline|c|, and
then using the tensorate of \lstinline|S.F|.
Using the evaluation for \lstinline|c i| at the basis element indicated by \lstinline|x| (if \lstinline|x| is too big a natural number for the number of basis elements it defaults to \lstinline|0|), we then get a vector in
\lstinline|𝟙 ⊗ S.F.obj (OverColor.mk (c ∘ Fin.succAbove i))|.
This mapping should be thought of as occuring in the  category of modules over \lstinline|S.k|, rather then in 
\lstinline|Rep S.G S.k|, since the evaluation is not invariant under the group action.
We then fininally map  into \lstinline|S.F.obj (OverColor.mk (c ∘ Fin.succAbove i))| 
using the left-unitor.

The main reason tensor trees are nice to work with is that they have the following property: 
Define a sub-tree of a tensor trees 
to be a node and all child nodes of that node. 
If $T$ is a tensor tree and $S$ a sub-tree of $T$, we can replace $S$ in $T$ 
with another tensor tree $S'$
to get a new overall tensor-tree $T'$. If $S$ and $S'$ have the same underlying tensor, 
then $T$ and $T'$ will. 

In Lean this property manifests in a series of lemmas. For instance, for instance 
for the \lstinline|contr| constructor we have the lemma: 
\begin{code}
lemma contr_tensor_eq {n : ℕ} {c : Fin n.succ.succ → S.C} {T1 T2 : TensorTree S c}
    (h : T1.tensor = T2.tensor) {i : Fin n.succ.succ} {j : Fin n.succ}
    {h' : c (i.succAbove j) = S.τ (c i)} :
    (contr i j h' T1).tensor = (contr i j h' T2).tensor := by
  simp only [Nat.succ_eq_add_one, contr_tensor]
  rw [h]
\end{code}
These lemmas allow us to navigate to the certain places in tensor trees and replace 
sub-trees with other sub-trees. We will see this used exensively in the examples. 

\subsection{Syntax and their map to tensor trees}


We now dicuss how we make the Lean code look similar to what we would use on pen-and-paper physics. 

This is done using a two step process. Firstly, we define syntax for tensor expressions. 
Then we write code to turn this syntax into a tensor tree. This process is not formally defined or 
verified, Lean takes the outputed tensor tree as the formal object to work with.

Instead of deleving into the nitty-gritty details of how this process works under the hood, 
we give some examples to see how it works. 

In what follows we will assume that $T$, and $T_i$ etc are tensors defined as $S.F.obj \_$ for 
some tensor species $S$. We will also assume that these tensors are defined correctly for the expressions below 
to make sense.

The syntax allows us to write the following 
\syntaxElab{\lstinline!\{T | μ ν\}ᵀ!}{{\lstinline!tensorNode T!}}
for a tensor node. Here the $\mu$ and $\nu$ are free variables and it does not 
matter what we call them - Lean will elaborate the expression in the same way.
The elaborator also knows how many indices to expect for a tensor $T$ and will raise an error if
the wrong number are given. The \lstinline|{_}ᵀ| notation is used to tell Lean that the syntax
is to be treated as a tensor expression. 

We can write e.g. 
\syntaxElab{\lstinline!\{T | μ ν\}ᵀ.tensor!}{{\lstinline!(tensorNode T).tensor!}}
to get the underlying tensor.

Note that we have not lowered or risen the indices, as one would expect from pen-and-paper notation.
There is one primary reason for this, whether an index is lower or risen does not carry any information, 
since this information comes from the tensor itself. Also, for something like complex Lorentz tensors, 
there are at least three different types of upper-index. 

We can extract the tensor from a tensor tree using the following syntax
If we want to evaluate an index we can put an explicit index in place of $\mu$ or $\nu$ above, 
for example
\syntaxElab{\lstinline!\{T | 1 ν\}ᵀ!}{\lstinline!eval 0 1 (tensorNode T)!}

The syntax and elaboration for negation, scalar multiplication and the group action 
are fairly similar. For negation we have 
\syntaxElab{\lstinline!\{T | μ ν\}ᵀ!}{\lstinline!neg (tensorNode T)!}
For scalar multiplication by $a \in k$ we have 
\syntaxElab{\lstinline!\{a •ₜ T | μ ν\}ᵀ!}{\lstinline!smul a (tensorNode T)!}
For the group action of $g\in G$ on a tensor $T$ we have
\syntaxElab{\lstinline!\{g •ₐ T | μ ν\}ᵀ!}{\lstinline!action g (tensorNode T)!}

For the product of two tensors is also fairly simple, we have 
\syntaxElab{\lstinline!\{T | μ ν ⊗ T2 | σ\}ᵀ!}{\lstinline!prod (tensorNode T) (tensorNode T2)!}

The syntax for contraction is as one expect, 
\syntaxElab{\lstinline!\{T | μ ν ⊗ T2 | ν σ\}ᵀ!}{\lstinline!contr 1 1 rfl (prod (tensorNode T) (tensorNode T2))!}
On the RHS here the first argument (\lstinline!1!) of \lstinline!contr! is the index of the first \lstinline|ν| on the LHS, 
the second argument  (also \lstinline!1!) is the second index. The \lstinline!rfl! is a proof that the
colors of the two contracted indices are actually dual to one another. If they are not, this proof will 
fail and the elaborator will complain. It will also complain if more then two indices are traying 
to be contracted. Although, this depends on where exactly the indices sit in the expression. For example 
\syntaxElab{\lstinline!\{T | μ ν ⊗ T2 | ν ν\}ᵀ!}{\lstinline!(prod (tensorNode T) (contr 0 0 rfl (tensorNode T2)))!}
works fine becuase the inner contraction is done before the product. 

We now turn to addition. Our syntax allows for e.g. \lstinline!{T | μ ν + T2 | μ ν}ᵀ! and also 
\lstinline!{T | μ ν + T2 | ν μ}ᵀ!, provided of course that the indices are of the correct color (which Lean will check). 
The elabor handles both these cases, and generalizations thereof by adding a permutation node. Thus we have 
\syntaxElab{\lstinline!\{T | μ ν + T2 | μ ν\}ᵀ!}{\lstinline!add (tensorNode T) (perm _ (tensorNode T2))!}
where here the \lstinline!_! is a placeholder for the permutation, and in this case will be trivial, but for 
\syntaxElab{\lstinline!\{T | μ ν + T2 | ν μ\}ᵀ!}{\lstinline!add (tensorNode T) (perm _ (tensorNode T2))!}
it will be the permutation for the two indentities. 

Despite not forming part of a node in our tensor tree, we also give syntax for equalitiy. 
This is done in a very similar way to addition, with the addition of a permutation node to account for
e.g. the fact that $T_{\mu \nu} = T_{\nu \mu}$. 
\syntaxElab{\lstinline!\{T | μ ν = T2 | ν μ\}ᵀ!}{\lstinline!(tensorNode T).tensor = (perm _ (tensorNode T2)).tensor!}
Note the use of the \lstinline!.tensor! to extract the tensor from the tensor tree, it does not really mean much 
to ask for equalitiy of the tensor trees themselves. 

\section{Examples} \label{sec:examples}

We give two examples in this section. The first example is a simple theorem involving index notation and 
tensor trees. We will show here, in rather explicit detail, how we can manipulate tensor trees to solve 
such theorems. 
The second example we shall give will show a number of definitions in HepLean concerning index notation.
Here we will not give so much detail, the point rather being to show the reader the broad use of our 
construction. 

\subsection{Example 1: Symmetric and anti-symmetric tensor} \label{sec:exampleSymmAntiSymm}
If $A^{\mu \nu}$ is an anti-symmetric tensor and $S_{\mu \nu}$ and $S$ is a symmetric tensor, then
it is true that $A^{\mu \nu} S_{\mu \nu} = - A^{\mu \nu} S_{\mu \nu}$. In Lean this result, and 
it's lemma are written as follows: 
\begin{code}
lemma antiSymm_contr_symm 
    {A : complexLorentzTensor.F.obj (OverColor.mk ![Color.up, Color.up])}
    {S : complexLorentzTensor.F.obj (OverColor.mk ![Color.down, Color.down])}
    (hA : {A | μ ν = - (A | ν μ)}ᵀ) (hs : {S | μ ν = S | ν μ}ᵀ) :
    {A | μ ν ⊗ S | μ ν = - A | μ ν ⊗ S | μ ν}ᵀ := by
  conv =>
    lhs
    rw [contr_tensor_eq <| contr_tensor_eq <| prod_tensor_eq_fst <| hA]
    rw [contr_tensor_eq <| contr_tensor_eq <| prod_tensor_eq_snd <| hs]
    rw [contr_tensor_eq <| contr_tensor_eq <| prod_perm_left _ _ _ _]
    rw [contr_tensor_eq <| contr_tensor_eq <| perm_tensor_eq <| prod_perm_right _ _ _ _]
    rw [contr_tensor_eq <| contr_tensor_eq <| perm_perm _ _ _]
    rw [contr_tensor_eq <| perm_contr_congr 1 2]
    rw [perm_contr_congr 0 0]
    rw [perm_tensor_eq <| contr_contr _ _ _]
    rw [perm_perm]
    rw [perm_tensor_eq <| contr_tensor_eq <| contr_tensor_eq <| neg_fst_prod _ _]
    rw [perm_tensor_eq <| contr_tensor_eq <| neg_contr _]
    rw [perm_tensor_eq <| neg_contr _]
  apply perm_congr _ rfl
  decide
\end{code}
Let us break this down. The statements 
\begin{code} 
{A : complexLorentzTensor.F.obj (OverColor.mk ![Color.up, Color.up])}
{S : complexLorentzTensor.F.obj (OverColor.mk ![Color.down, Color.down])}
\end{code}
are simply defining $A$ and $S$ to be tensors of type $A^{\mu \nu}$ and $S_{\mu \nu}$ respectively.
This agrees with the notation set out in \S\ref{} \js{ref}.

The parameter \lstinline|hA| is stating that $A$ is anti-symmetric. Expanded in terms of tree diagrams 
we have
\proofstep{\lstinline!hA : \{A | μ ν = - (A | ν μ)\}ᵀ!}{Description: The tensor $A$ 
  is anti-symmetric.}{
 \begin{tikzpicture}
    \node[draw=black] (A) at (-2,-1) {A};
    \node[draw=black] (D1) at (0,0) {perm};
    \node[draw=black] (E1) at (0,-1) {neg};
    \node[draw=black] (F1) at (0,-2) {A};
    \node (eq) at (-1, -1) {$=$};
    \path [->] (D1) edge (E1);
    \path [->] (E1) edge (F1);
  \end{tikzpicture} 
}
Similarly, the parameter \lstinline|hs| is stating that $S$ is symmetric. Expanded in terms of tree diagrams
\proofstep{\lstinline!hS : \{S | μ ν = S | ν μ\}ᵀ!}{Description: The tensor \lstinline|S|
  is symmetric.}{
 \begin{tikzpicture}
    \node[draw=black] (A) at (-2,-0.5) {S};
    \node[draw=black] (D1) at (0,0) {perm};
    \node[draw=black] (F1) at (0,-1) {S};
    \node (eq) at (-1, -0.5) {$=$};
    \path [->] (D1) edge (F1);
  \end{tikzpicture} 
}

The line \lstinline!{A | μ ν ⊗ S | μ ν = - A | μ ν ⊗ S | μ ν}ᵀ! is the statment we are trying to prove. 
In terms of tree diagrams it says that 
\begin{center}
\begin{tikzpicture}
  \node (eq) at (2.5,-1) {$=$};
  \node (t1) at (1.5,-1) {\lstinline|.tensor|};
  \node (t2) at (5.5,-1) {\lstinline|.tensor|};
  \node[draw=black] (A) at (0,0) {contr 0 0};
  \node[draw=black] (B) at (0,-1) {contr 0 1};
  \node[draw=black] (C) at (0,-2) {prod};
  \node[draw=black] (D1) at (-1,-3) {A};
  \node[draw=black] (D2) at (1,-3) {S};
  \path [->] (A) edge (B);
  \path [->] (B) edge (C);
  \path [->] (C) edge (D1);
  \path [->] (C) edge (D2);
  \node[draw=black] (P') at (4,1) {perm $\_$};
  \node[draw=black] (N') at (4,0) {neg};
  \node[draw=black] (A') at (4,-1) {contr 0 0};
  \node[draw=black] (B') at (4,-2) {contr 0 1};
  \node[draw=black] (C') at (4,-3) {prod};
  \node[draw=black] (D1') at (3,-4) {A};
  \node[draw=black] (D2') at (5,-4) {S};
  \path [->] (P') edge (N');
  \path [->] (N') edge (A');
  \path [->] (A') edge (B');
  \path [->] (B') edge (C');
  \path [->] (C') edge (D1');
  \path [->] (C') edge (D2');
\end{tikzpicture}
\end{center}
The perm here actually does nothing, but is included by Lean. 

The lines of the proof in the \lstinline|conv| block are manipulations of the tensor tree on the 
LHS of the equation. The \lstinline|rw| tactic is used to rewrite the tensor tree using the various lemmas. 
We go through each step in turn. 
\proofstep{\lstinline!rw [contr_tensor_eq <| contr_tensor_eq <| prod_tensor_eq_fst <| hA]!}{
  Description: Replace the node \lstinline|A| with the RHS of \lstinline|hA|.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {contr 0 0};
    \node[draw=black] (B) at (0,-1) {contr 0 1};
    \node[draw=black] (C) at (0,-2) {prod};
    \node[draw=red] (D1) at (-1,-3) {perm};
    \node[draw=red] (E1) at (-1,-4) {neg};
    \node[draw=red] (F1) at (-1,-5) {A};
    \node[draw=black] (D2) at (1,-3) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->] (C) edge (D1);
    \path [->, color = red] (D1) edge (E1);
    \path [->, color = red] (E1) edge (F1);
    \path [->] (C) edge (D2);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [contr_tensor_eq <| contr_tensor_eq <| prod_tensor_eq_snd <| hs]!}{
  Description: Replace the node \lstinline|S| with the RHS of \lstinline|hS|.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {contr 0 0};
    \node[draw=black] (B) at (0,-1) {contr 0 1};
    \node[draw=black] (C) at (0,-2) {prod};
    \node[draw=black] (D1) at (-1,-3) {perm};
    \node[draw=black] (E1) at (-1,-4) {neg};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=red] (D2) at (1,-3) {perm};
    \node[draw=red] (F2) at (1,-4) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->] (C) edge (D1);
    \path [->] (D1) edge (E1);
    \path [->] (E1) edge (F1);
    \path [->] (C) edge (D2);
    \path [->, color=red] (D2) edge (F2);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [contr_tensor_eq <| contr_tensor_eq <| prod_perm_left _ _ _ _]!}{
  Description: Move the left permutation through the product.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {contr 0 0};
    \node[draw=black] (B) at (0,-1) {contr 0 1};
    \node[draw=red] (C) at (0,-2) {perm};
    \node[draw=red] (D) at (0,-3) {prod};
    \node[draw=black] (E1) at (-1,-4) {neg};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (E2) at (1,-4) {perm};
    \node[draw=black] (F2) at (1,-5) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->, color = red] (C) edge (D);
    \path [->, color = red] (D) edge (E1);
    \path [->] (E1) edge (F1);
    \path [->] (D) edge (E2);
    \path [->] (E2) edge (F2);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [contr_tensor_eq <| contr_tensor_eq <| perm_tensor_eq <| prod_perm_right _ _ _ _]!}{
  Description: Move the right permutation through the product.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {contr 0 0};
    \node[draw=black] (B) at (0,-1) {contr 0 1};
    \node[draw=black] (C) at (0,-2) {perm};
    \node[draw=red] (D) at (0,-3) {perm};
    \node[draw=red] (E) at (0,-4) {prod};
    \node[draw=black] (F1) at (-1,-5) {neg};
    \node[draw=black] (G1) at (-1,-6) {A};
    \node[draw=black] (F2) at (1,-5) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->] (C) edge (D);
    \path [->, color = red] (D) edge (E);
    \path [->] (E) edge (F1);
    \path [->, color = red] (E) edge (F2);
    \path [->] (F1) edge (G1);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [contr_tensor_eq <| contr_tensor_eq <| perm_perm _ _ _]!}{
  Description: Combine the two permutations (using functoriality).
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {contr 0 0};
    \node[draw=black] (B) at (0,-1) {contr 0 1};
    \node[draw=red] (C) at (0,-2) {perm};
    \node[draw=black] (D) at (0,-3) {prod};
    \node[draw=black] (E1) at (-1,-4) {neg};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (E2) at (1,-4) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->] (C) edge (D);
    \path [->] (D) edge (E1);
    \path [->] (D) edge (E2);
    \path [->] (E1) edge (F1);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [contr_tensor_eq <| perm_contr_congr 1 2]!}{
  Description: Move the permutation through the contraction. And simplify the contraction 
  indices to \lstinline|1| and \lstinline|2| (Lean will check if this is correct).
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {contr 0 0};
    \node[draw=red] (B) at (0,-1) {perm};
    \node[draw=red] (C) at (0,-2) {contr 1 2};
    \node[draw=black] (D) at (0,-3) {prod};
    \node[draw=black] (E1) at (-1,-4) {neg};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (E2) at (1,-4) {S};
    \path [->] (A) edge (B);
    \path [->, color = red] (B) edge (C);
    \path [->, color = red] (C) edge (D);
    \path [->] (D) edge (E1);
    \path [->] (D) edge (E2);
    \path [->] (E1) edge (F1);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [perm_contr_congr 0 0]!}{
  Description: Move the permutation through the contraction. And simplify the contraction 
  indices to \lstinline|0| and \lstinline|0| (Lean will check if this is correct).
}{
  \begin{tikzpicture}
    \node[draw=red] (A) at (0,0) {perm};
    \node[draw=red] (B) at (0,-1) {contr 0 0};
    \node[draw=black] (C) at (0,-2) {contr 1 2};
    \node[draw=black] (D) at (0,-3) {prod};
    \node[draw=black] (E1) at (-1,-4) {neg};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (E2) at (1,-4) {S};
    \path [->, color = red] (A) edge (B);
    \path [->, color = red] (B) edge (C);
    \path [->] (C) edge (D);
    \path [->] (D) edge (E1);
    \path [->] (D) edge (E2);
    \path [->] (E1) edge (F1);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [perm_tensor_eq <| contr_contr _ _ _]!}{
  Description: Swap the two contractions. This introduces a permutation.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {perm};
    \node[draw=red] (A') at (0,-1) {perm};
    \node[draw=red] (B) at (0,-2) {contr 0 0};
    \node[draw=red] (C) at (0,-3) {contr 0 1};
    \node[draw=black] (D) at (0,-4) {prod};
    \node[draw=black] (E1) at (-1,-5) {neg};
    \node[draw=black] (F1) at (-1,-6) {A};
    \node[draw=black] (E2) at (1,-5) {S};
    \path [->] (A) edge (A');
    \path [->, color = red] (A') edge (B);
    \path [->, color = red] (B) edge (C);
    \path [->, color = red] (C) edge (D);
    \path [->] (D) edge (E1);
    \path [->] (D) edge (E2);
    \path [->] (E1) edge (F1);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [perm_perm]!}{
  Description: Combine the two permutations.
}{
  \begin{tikzpicture}
    \node[draw=red] (A) at (0,0) {perm};
    \node[draw=black] (B) at (0,-1) {contr 0 0};
    \node[draw=black] (C) at (0,-2) {contr 0 1};
    \node[draw=black] (D) at (0,-3) {prod};
    \node[draw=black] (E1) at (-1,-4) {neg};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (E2) at (1,-4) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->] (C) edge (D);
    \path [->] (D) edge (E1);
    \path [->] (D) edge (E2);
    \path [->] (E1) edge (F1);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [perm_tensor_eq <| contr_tensor_eq <| contr_tensor_eq <| neg_fst_prod _ _]!}{
  Description: Move the negation through the product.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {perm};
    \node[draw=black] (B) at (0,-1) {contr 0 0};
    \node[draw=black] (C) at (0,-2) {contr 0 1};
    \node[draw=red] (D) at (0,-3) {neg};
    \node[draw=red] (E) at (0,-4) {prod};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (F2) at (1,-5) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->] (C) edge (D);
    \path [->, color = red] (D) edge (E);
    \path [->, color = red] (E) edge (F1);
    \path [->] (E) edge (F2);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [perm_tensor_eq <| contr_tensor_eq <| neg_contr _]!}{
  Description: Move the negation through the first contraction.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {perm};
    \node[draw=black] (B) at (0,-1) {contr 0 0};
    \node[draw=red] (C) at (0,-2) {neg};
    \node[draw=red] (D) at (0,-3) {contr 0 1};
    \node[draw=black] (E) at (0,-4) {prod};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (F2) at (1,-5) {S};
    \path [->] (A) edge (B);
    \path [->] (B) edge (C);
    \path [->, color = red] (C) edge (D);
    \path [->, color = red] (D) edge (E);
    \path [->] (E) edge (F1);
    \path [->] (E) edge (F2);
  \end{tikzpicture}
}

\proofstep{\lstinline!rw [perm_tensor_eq <| neg_contr _]!}{
  Description: Move the negation through the second contraction.
}{
  \begin{tikzpicture}
    \node[draw=black] (A) at (0,0) {perm};
    \node[draw=red] (B) at (0,-1) {neg};
    \node[draw=red] (C) at (0,-2) {contr 0 0};
    \node[draw=black] (D) at (0,-3) {contr 0 1};
    \node[draw=black] (E) at (0,-4) {prod};
    \node[draw=black] (F1) at (-1,-5) {A};
    \node[draw=black] (F2) at (1,-5) {S};
    \path [->] (A) edge (B);
    \path [->, color = red] (B) edge (C);
    \path [->, color = red] (C) edge (D);
    \path [->] (D) edge (E);
    \path [->] (E) edge (F1);
    \path [->] (E) edge (F2);
  \end{tikzpicture}
}

The remainder of the proof \lstinline|apply perm_congr _ rfl| and \lstinline|decide| that the 
tensor trees on the LHS and RHS are actually equal.
\subsection{Example 2: Pauli matrices and bispinors} \label{sec:examplePauliBispinor}

Using the formlism we have set up thus far it is possible to define Pauli matrices and bispinors 
as complex Lorentz tensors.
 
The pauli matrices appear in HepLean as follows 
\begin{code}
/-- The Pauli matrices as the complex Lorentz tensor `σ^μ^α^{dot β}`. -/
def pauliContr := {PauliMatrix.asConsTensor | ν α β}ᵀ.tensor

/-- The Pauli matrices as the complex Lorentz tensor `σ_μ^α^{dot β}`. -/
def pauliCo := {η' | μ ν ⊗ pauliContr | ν α β}ᵀ.tensor

/-- The Pauli matrices as the complex Lorentz tensor `σ_μ_α_{dot β}`. -/
def pauliCoDown := {pauliCo | μ α β ⊗ εL' | α α' ⊗ εR' | β β'}ᵀ.tensor

/-- The Pauli matrices as the complex Lorentz tensor `σ^μ_α_{dot β}`. -/
def pauliContrDown := {pauliContr | μ α β ⊗ εL' | α α' ⊗ εR' | β β'}ᵀ.tensor
\end{code}
The first of these definitions depends on \lstinline|PauliMatrix.asConsTensor| which is defined as 
using an explcit basis expansion. 

In these expressions we have the appearence of metrics \lstinline|η'| is the metric usually written as 
$\eta_{\mu \nu}$, \js{etc.}

With these we can define bispinors 
\begin{code}
/-- A bispinor `pᵃᵃ` created from a lorentz vector `p^μ`. -/
def contrBispinorUp (p : complexContr) :=
  {pauliCo | μ α β ⊗ p | μ}ᵀ.tensor

/-- A bispinor `pₐₐ` created from a lorentz vector `p^μ`. -/
def contrBispinorDown (p : complexContr) :=
  {εL' | α α' ⊗ εR' | β β' ⊗ contrBispinorUp p | α β}ᵀ.tensor

/-- A bispinor `pᵃᵃ` created from a lorentz vector `p_μ`. -/
def coBispinorUp (p : complexCo) := {pauliContr | μ α β ⊗ p | μ}ᵀ.tensor

/-- A bispinor `pₐₐ` created from a lorentz vector `p_μ`. -/
def coBispinorDown (p : complexCo) :=
  {εL' | α α' ⊗ εR' | β β' ⊗ coBispinorUp p | α β}ᵀ.tensor
\end{code}
Here \lstinline|complexContr| and \lstinline|complexCo| are complex contravariant and covariant Lorentz vectors.
Lean knows to treat these as tensors when they appear in tensor expressions. 


Using these definitions we can start to prove results about the pauli matrices and bispinors. 
These proofs reyl on essentially the sorts of manipulations in the last section, although in some cases 
we expand tensors in terms of a basis and use rules about how the basis interacts with the operations in a tensor tree. 

Examples of things we have proven range  
\begin{code}
lemma coBispinorDown_eq_pauliContrDown_contr (p : complexCo) :
  {coBispinorDown p | α β = pauliContrDown | μ α β ⊗ p | μ}ᵀ := by
\end{code}
the proof of which is an application of associativity of the tensor product, and appropratly shuffling 
around of the contractions. 

To more complicated results such as
\begin{code}
/-- The statement that `η_{μν} σ^{μ α dot β} σ^{ν α' dot β'} = 2 ε^{αα'} ε^{dot β dot β'}`. -/
theorem pauliCo_contr_pauliContr :
    {pauliCo | ν α β ⊗ pauliContr | ν α' β' = 2 •ₜ εL | α α' ⊗ εR | β β'}ᵀ := by
\end{code}


\section{Future work} \label{sec:future}
The scale of formalizing all results regarding index notation is a task that surpasses 
the capacity of any single individual. Inspired by the Lean community's 
blueprint projects, we have added to HepLean informal lemmas related to index notation and tensors. 
An example of such is 
\begin{code} 
informal_lemma coBispinorUp_eq_metric_contr_coBispinorDown where
  math :≈ "{coBispinorUp p | α β = εL | α α' ⊗ εR | β β' ⊗ coBispinorDown p | α' β' }ᵀ"
  proof :≈ "Expand `coBispinorDown` and use fact that metrics contract to the identity."
  deps :≈ [``coBispinorUp, ``coBispinorDown, ``leftMetric, ``rightMetric]
\end{code}
The lemmas  resource that we hope others—or even automated systems—will formalize in the future.

As demonstrated in our earlier examples, manipulating tensor expressions can involve tedious
 calculations, especially when dealing with directly with tensor trees. 
In the future, we intend to automate many of these routine steps by developing suitable tactics 
within Lean. We are optimistic that the structured nature of tensor trees will lend itself well to 
such automation, thereby streamlining computations and enhancing the efficiency of formal proofs
involving index notation and tensor species.

There are two primary directions in which we can extend the concepts presented in this work. 
First, we could incorporate the spinor-helicity formalism, which is used in the study of scattering 
amplitudes. Second, we could extend our approach to encompass tensor \emph{fields}, their derivatives
etc. We do not anticipate any insurmountable challenges in pursuing these extensions. 
They represent promising avenues for future research and have the potential to significantly enhance
the utility of formal methods in physics.
\bibliographystyle{unsrturl}
\begin{spacing}{0.5}
\bibliography{MyBib}
\end{spacing}
%%%%%%%%%%%%%%
\end{document}
